{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset multi-layer perceptron\n",
    "* mnsit is handwriten character data built into tensorflow and used for testing. The data is stored in the from of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-b02c9870ee5b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/fabian/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/fabian/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/fabian/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/fabian/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/fabian/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/fabian/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = mnist.train.images[2].reshape(28,28)\n",
    "#reshape to original size to see the actual data values which is the darkeness of the pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Example of what the image actually looks like.\n",
    "plt.imshow(sample,cmap='Greys');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I wil develop a multi-layer percepton in TensorFlow to take in pixel information and correctly classify it to the number represented in the mnsit image.\n",
    "#### Define Parameters\n",
    "* Learning Rate - How quickly to adjust the cost function.\n",
    "* Training Epochs - How many training cycles to go through\n",
    "* Batch Size - Size of the 'batches' of training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#network Parameters\n",
    "n_classes = 10 \n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the actual input shape which is the flattened 28*28\n",
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stored in 8bit color storage\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#multilayer perceptron, uses rectifier function\n",
    "def multilayer_perceptron(x,weight,biases):\n",
    "    \"\"\"\n",
    "    x: placeholder for data input\n",
    "    weights: dict of weights\n",
    "    biases: dict of bias values\n",
    "    \"\"\"\n",
    "    \n",
    "    #First hidden Layer with RELU Activation\n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    # RELU(X * W + B) => f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    #2nd hidden layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    #last output layer\n",
    "    out_layer = tf.matmul(layer_2,weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    #randomly initialized normal matrix for hidden layer 1,n_input = 784rows and n_hidden_1 = 256cols\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    #second layer takes in 1st layer\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    # output will be: [0,0,0,0,0,1,0,0,0,0] for the number 6 \n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    #vlaues added to weights multipled by the data in perceptron\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set 2 placeholders for x,y; (type,shape)\n",
    "x = tf.placeholder('float',[None,n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder('float', [None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information on the data out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1) \n",
    "#samples of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsamp,ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c285183c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp\n",
    "#the 6th position in the array is true for 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#init = tf.initialize_all_variables() -> deprecated\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost 0.5251\n",
      "Epoch: 2 cost 0.4853\n",
      "Epoch: 3 cost 0.4894\n",
      "Epoch: 4 cost 0.4543\n",
      "Epoch: 5 cost 0.4063\n",
      "Epoch: 6 cost 0.3894\n",
      "Epoch: 7 cost 0.3789\n",
      "Epoch: 8 cost 0.3913\n",
      "Epoch: 9 cost 0.2934\n",
      "Epoch: 10 cost 0.2966\n",
      "Epoch: 11 cost 0.2751\n",
      "Epoch: 12 cost 0.2737\n",
      "Epoch: 13 cost 0.2673\n",
      "Epoch: 14 cost 0.2685\n",
      "Epoch: 15 cost 0.2434\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "#15 loops\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    #start with cost\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _,c = sess.run([optimizer,cost],feed_dict={x:batch_x, y:batch_y})\n",
    "\n",
    "        \n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch: {} cost {:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions,'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mnist.test.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9498"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x:mnist.test.images,y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95% accuracy on 15  epochs is ok. this would certainly improve with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
